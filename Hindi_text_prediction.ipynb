{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpSLSbemPBpo",
        "outputId": "63998b8d-1ee9-4a22-f1c3-00be52d135f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 34s 127ms/step - loss: 1.5558 - accuracy: 0.4634 - val_loss: 1.4774 - val_accuracy: 0.4620\n",
            "17/17 [==============================] - 1s 25ms/step\n",
            "Accuracy: 0.4619666048237477\n",
            "Precision: 0.3074588783483662\n",
            "Recall: 0.4619666048237477\n",
            "F1 Score: 0.30453656262316514\n",
            "1/1 [==============================] - 0s 31ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# necessary libraries that I thought\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Here reading the data set, I am reading both here only\n",
        "train_data = pd.read_csv('Hindi_train.csv')\n",
        "test_data = pd.read_csv('hindi_test.csv')\n",
        "\n",
        "\n",
        "#some little preprocessing\n",
        "#I creted the lebels \"Text\" and \"Sentiment\" as it was not in the data set\n",
        "X_train = train_data['Sentence'].astype(str)\n",
        "X_test = test_data['Sentence'].astype(str)\n",
        "\n",
        "# As computers dont undertand words, converting it into numbers               #note I tried first with words:p\n",
        "label_mapping = {'joy': 1, 'neutral': 0, 'surprise': 2, 'fear': 3, 'disgust' :4 , 'anger' :5, 'sadness' : 6}\n",
        "\n",
        "y_train = train_data['Label'].map(label_mapping)\n",
        "y_test = test_data['Label'].map(label_mapping)\n",
        "\n",
        "# TF-IDF learnt in NLP, I liked this\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Simply taken Naive bayes fucntion from sklearn\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Evaluation thing I checked\n",
        "y_pred_nb = nb_classifier.predict(X_test_tfidf)\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "precision_nb = precision_score(y_test, y_pred_nb, average='weighted')\n",
        "recall_nb = recall_score(y_test, y_pred_nb, average='weighted')\n",
        "f1_nb = f1_score(y_test, y_pred_nb, average='weighted')\n",
        "\n",
        "# LSTM model, took help\n",
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=200)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=200)\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=64, input_length=200),\n",
        "    LSTM(64),\n",
        "    Dense(7, activation='softmax')  # softmax for LSTM\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_pad, y_train, epochs=1, batch_size=32, validation_data=(X_test_pad, y_test))\n",
        "\n",
        "# Evaluatoin kinda same as above checked the difference\n",
        "y_pred_dl_prob = model.predict(X_test_pad)\n",
        "y_pred_dl = y_pred_dl_prob.argmax(axis=-1)\n",
        "accuracy_dl = accuracy_score(y_test, y_pred_dl)\n",
        "precision_dl = precision_score(y_test, y_pred_dl, average='weighted')\n",
        "recall_dl = recall_score(y_test, y_pred_dl, average='weighted')\n",
        "f1_dl = f1_score(y_test, y_pred_dl, average='weighted')\n",
        "\n",
        "\n",
        "new_text = \"I am sad\"    #took a text, real life incident\n",
        "\n",
        "\n",
        "#prediction work\n",
        "new_text_tfidf = tfidf_vectorizer.transform([new_text])\n",
        "predicted_sentiment_nb = nb_classifier.predict(new_text_tfidf)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_dl)\n",
        "print(\"Precision:\", precision_dl)\n",
        "print(\"Recall:\", recall_dl)\n",
        "print(\"F1 Score:\", f1_dl)\n",
        "\n",
        "\n",
        "new_text_seq = tokenizer.texts_to_sequences([new_text])\n",
        "new_text_pad = pad_sequences(new_text_seq, maxlen=200)\n",
        "predicted_sentiment_dl_prob = model.predict(new_text_pad)\n",
        "predicted_sentiment_dl = predicted_sentiment_dl_prob.argmax(axis=-1)\n"
      ]
    }
  ]
}